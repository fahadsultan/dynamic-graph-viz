{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26K5b1UOSpeT",
        "outputId": "d0db6c16-fac6-4468-96ab-b6b613f86684"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import networkx as nx\n",
        "%matplotlib inline\n",
        "!pip3 install netgraph\n",
        "from netgraph import Graph\n",
        "!pip install fdeb\n",
        "from fdeb import fdeb\n",
        "import matplotlib.collections as collections\n",
        "import math\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxvsLAwoyfUN"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8gk5prfyrmI"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Flatten pixels\n",
        "X_train = X_train.reshape((-1, 784))\n",
        "X_test = X_test.reshape((-1, 784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfa4zA5o5w6m",
        "outputId": "6e10a107-eb1f-4bbd-d159-cfb68f06a334"
      },
      "outputs": [],
      "source": [
        "# tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=784),\n",
        "    # tf.keras.layers.Conv2D(4, 4)\n",
        "    tf.keras.layers.Dense(10, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(5, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=1, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6NOrK6uy8ZW"
      },
      "outputs": [],
      "source": [
        "# #This cell gets the input and output names for the first and last layer\n",
        "# input_names = enumerate(iris[\"feature_names\"])\n",
        "# ind_input_names = {}\n",
        "\n",
        "# for i, name in input_names:\n",
        "#   ind_input_names[i] = name.split()[0] + ' ' + name.split()[1]\n",
        "\n",
        "# target_names = enumerate(iris[\"target_names\"])\n",
        "\n",
        "# ind_output_names = {}\n",
        "\n",
        "# for i, name in target_names:\n",
        "#   ind_output_names[i] = name\n",
        "# ind_output_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7mTt4Dk_7UW"
      },
      "source": [
        "### Arbitrarily ordered Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXdw6fTOAGPj"
      },
      "outputs": [],
      "source": [
        "# Assuming you have Ws defined earlier, and Ws[-1] contains W1 and W2\n",
        "# Define the weight matrices (taken from Ws[-1])\n",
        "weights = model.weights\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "pos = {}\n",
        "\n",
        "i = 0\n",
        "z = 0\n",
        "maxRows = 0\n",
        "for z in range(len(weights)):\n",
        "  maxRows = max(maxRows, weights[z].shape[0])\n",
        "  z += 2\n",
        "\n",
        "maxRows += 1\n",
        "\n",
        "colSize = [] #put in to allow for edge_label placement\n",
        "\n",
        "col = 0\n",
        "while i < len(weights):\n",
        "  w = weights[i] #w are weights associated between two layers\n",
        "  colSize.append(w.shape[0])  #puts size of dest column in the list, helps with edge label positioning\n",
        "\n",
        "  for sourceRow in range(w.shape[0]):\n",
        "\n",
        "    # if col == 0: # makes the first layer of nodes' names input the variables\n",
        "    #   # rows and columns are kept in the name to help with determining pos\n",
        "    #   source_node = ind_input_names[sourceRow] + '_' + str(sourceRow) + '_' + str(col)\n",
        "    # else: #Used for every layer but the first\n",
        "    source_node = 'l_' + str(sourceRow) + '_' + str(col)\n",
        "\n",
        "    # w.shape[0] is the length of the source column\n",
        "    pos[source_node] = (col, maxRows/(w.shape[0] + 1) * (sourceRow + 1) * -5) # zero div prevented\n",
        "\n",
        "    for row in range(w.shape[1]):\n",
        "      # if (col + 1) == len(weights)//2: # if we are at the last layer, node names are made to be the output\n",
        "      #   dest_node = ind_output_names[row] + '_' + str(row) + '_' + str(col + 1)\n",
        "      # else:\n",
        "      dest_node = 'l_' + str(row) + '_' + str(col+1)\n",
        "\n",
        "      G.add_edge(source_node, dest_node, weight = w[sourceRow][row])\n",
        "      # w.shape[1] is length of the destination column\n",
        "      pos[dest_node] = (col + 1, maxRows/(w.shape[1] + 1) * (row + 1) * -5)  #zero div prevented\n",
        "\n",
        "  i += 2 # necessary to increment by 2 when using tensor flow\n",
        "  col += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0XgdvrpAgg7",
        "outputId": "17014251-c45b-447d-945a-17779341b7b6"
      },
      "outputs": [],
      "source": [
        "colSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "O128_FFyAKwr",
        "outputId": "1ac18284-18b0-4319-f60d-86769456f6f4"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "edge_colors = []\n",
        "alpha = []\n",
        "width = [] #width is defined here\n",
        "node_size = []\n",
        "dest_node_size = {}\n",
        "\n",
        "for u, v, d in G.edges(data=True):\n",
        "    if d['weight'] > 0:\n",
        "        edge_colors.append('black')\n",
        "    else:\n",
        "        edge_colors.append('red')\n",
        "\n",
        "    dest_node_size[v] =  dest_node_size.get(v, 0) + abs(d['weight'])\n",
        "    alpha.append(d['weight'])\n",
        "    width.append(d['weight'] ** 2) #thickness squared\n",
        "\n",
        "for node in G.nodes():\n",
        "  if node in dest_node_size.keys():\n",
        "    col = int(node.split('_')[2]) - 1\n",
        "    node_size.append(dest_node_size[node]/colSize[col] * 4000)\n",
        "  else:\n",
        "    node_size.append(1000)\n",
        "\n",
        "plt.figure(figsize=(40, 20))\n",
        "\n",
        "#handles: nodes, node size, node color,\n",
        "nx.draw_networkx_nodes(G, pos=pos, node_size=node_size, node_color='skyblue')\n",
        "\n",
        "#handles edges, edge thickness, and edge color\n",
        "nx.draw_networkx_edges(G, pos=pos, edge_color=edge_colors, arrows=True, width = width)\n",
        "\n",
        "# key = edge and val = weight\n",
        "edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "# # handles edge labels pos\n",
        "# for u, v in G.edges():\n",
        "#     specific_edge_labels = {(u, v): edge_labels[(u, v)]}\n",
        "#     row = int(u.split('_')[1])\n",
        "#     index = int(u.split('_')[2])\n",
        "#     nx.draw_networkx_edge_labels(G, pos, edge_labels=specific_edge_labels, font_color='black', font_size=12, label_pos = (row + 1) / (colSize[index]+2))\n",
        "\n",
        "#handles node labels\n",
        "nx.draw_networkx_labels(G, pos, font_size=18, font_color='purple', font_weight='bold')\n",
        "\n",
        "plt.title('MNIST Random Order')\n",
        "\n",
        "plt.axis('on')\n",
        "plt.margins(0.1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNze75E9BG3C"
      },
      "outputs": [],
      "source": [
        "springPos = nx.spring_layout(G, weight = 'weight', k = 1, iterations = 500)\n",
        "# nx.draw_networkx_edges(G, pos = springPos, edge_color = edge_colors);\n",
        "# nx.draw_networkx_nodes(G, pos = springPos);\n",
        "# nx.draw_networkx_labels(G, pos, font_size=8, font_color='purple', font_weight='bold')\n",
        "# plt.title(\"Spring graph\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGdqBTpWBJcy"
      },
      "outputs": [],
      "source": [
        "#puts the spring coordinates into a dataframe\n",
        "springPos = pd.Series(springPos)\n",
        "xVals, yVals = zip(*springPos)\n",
        "coordsS = pd.DataFrame({\n",
        "    'xVals' : xVals,\n",
        "    'yVals' : yVals\n",
        "})\n",
        "\n",
        "#associates the coords with their nodes\n",
        "coordsS.index = list(G.nodes())\n",
        "\n",
        "#combines the x and y coordinates into 1 values\n",
        "pca = PCA(n_components=1)\n",
        "y_pca = pca.fit_transform(coordsS)\n",
        "coordsS = pd.DataFrame({\n",
        "    'coords' : y_pca.flatten()\n",
        "    })\n",
        "\n",
        "#associates the coords with their nodes\n",
        "coordsS.index = list(G.nodes())\n",
        "#associates each node and y-val with a column\n",
        "coordsS['column'] = coordsS.apply(lambda x: x.name.split('_')[2], axis = 1)\n",
        "\n",
        "# sorts the nodes by columns and then pca values\n",
        "sorted_groups = coordsS.groupby('column', group_keys=False).apply(lambda x: x.sort_values('coords'))\n",
        "sorted_groups['group_index'] = sorted_groups.groupby('column').cumcount() #makes sorted values as group index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkBcLvENB5L8"
      },
      "source": [
        "NN dynamic layout graph based on Spring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc0EVXLoBzch"
      },
      "outputs": [],
      "source": [
        "weights = model.weights\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "pos = {}\n",
        "maxRow = sorted_groups['group_index'].max() + 2\n",
        "col    = 0\n",
        "i      = 0\n",
        "while i < len(weights):\n",
        "  w = weights[i] #w are weights associated with a col\n",
        "  for sourceRow in range(w.shape[0]):\n",
        "    # if col == 0: #if node is in the first layer, it makes the name the input val\n",
        "    #   source_node = ind_input_names[sourceRow] + '_' + str(sourceRow) + '_' + str(col)\n",
        "    # else:\n",
        "    source_node = 'l_' + str(sourceRow) + '_' + str(col)\n",
        "\n",
        "    if source_node not in pos.keys():\n",
        "      sourceColumn = sorted_groups.loc[source_node]['column']\n",
        "      colLength = (int(sorted_groups[sorted_groups['column'] \\\n",
        "        == sourceColumn]['group_index'].max()) + 2)\n",
        "      currRow = (sourceRow + 1)\n",
        "\n",
        "      pos[source_node] = (col, maxRow/colLength * currRow)\n",
        "\n",
        "    for row in range(w.shape[1]):\n",
        "      # if (col + 1) == len(weights)//2: # makes last layer node names = the output values\n",
        "      #   dest_node = ind_output_names[row] + '_' + str(row) + '_' + str(col + 1)\n",
        "      # else:\n",
        "      dest_node = 'l_' + str(row) + '_' + str(col+1)\n",
        "\n",
        "      G.add_edge(source_node, dest_node, weight = w[sourceRow][row])\n",
        "      if dest_node not in pos.keys(): #gives pos if needed\n",
        "        destColumn = sorted_groups.loc[dest_node]['column']\n",
        "        colLength = (int(sorted_groups[sorted_groups['column'] \\\n",
        "          == destColumn]['group_index'].max()) + 2)\n",
        "        currRow = sorted_groups.loc[dest_node]['group_index'] + 1\n",
        "\n",
        "        pos[dest_node] = (col + 1, maxRow/colLength * currRow)\n",
        "\n",
        "  i += 2\n",
        "  col += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "ufN0yjygB-zH",
        "outputId": "61bb26a3-856e-40d0-9fbf-1b5369286865"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40, 20))\n",
        "\n",
        "#nodes, nodes size, and node color\n",
        "nx.draw_networkx_nodes(G, pos=pos, node_size=node_size, node_color='skyblue')\n",
        "\n",
        "#edges, edge color, and edge width\n",
        "nx.draw_networkx_edges(G, pos=pos, edge_color=edge_colors, arrows=True, width = width)\n",
        "\n",
        "\n",
        "edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "# # edge labels and their positioning\n",
        "# for u, v in G.edges():\n",
        "#     specific_edge_labels = {(u, v): edge_labels[(u, v)]}\n",
        "#     row = int(u.split('_')[1])\n",
        "#     index = int(u.split('_')[2])\n",
        "#     nx.draw_networkx_edge_labels(G, pos, edge_labels=specific_edge_labels, font_color='black', font_weight = 'bold', font_size=12, label_pos = (row + 1) / (colSize[index]+2))\n",
        "\n",
        "#node names\n",
        "nx.draw_networkx_labels(G, pos, font_size=18, font_color='purple', font_weight='bold')\n",
        "\n",
        "plt.title('MNIST based on Spring')\n",
        "\n",
        "plt.axis('on')\n",
        "plt.margins(0.1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgoS5yzCTIG"
      },
      "source": [
        "### FDEB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Uc4V5_Gf5wC"
      },
      "outputs": [],
      "source": [
        "maxRow = sorted_groups['group_index'].max() + 2\n",
        "nodes_to_exclude = [node for node in G.nodes() if node.endswith(\"_0\")]\n",
        "G.remove_nodes_from(nodes_to_exclude)\n",
        "\n",
        "for node in nodes_to_exclude:\n",
        "  del pos[node]\n",
        "  node_size.remove(node)\n",
        "\n",
        "\n",
        "node_size = []\n",
        "for node in G.nodes():\n",
        "  if node in dest_node_size.keys():\n",
        "    col = int(node.split('_')[2]) - 1\n",
        "    node_size.append(dest_node_size[node]/colSize[col] * 4000)\n",
        "\n",
        "\n",
        "# for key, val in pos.items():\n",
        "#   if key in sorted_groups.index:\n",
        "#     row = int(key.split('_')[1])\n",
        "#     col = sorted_groups.loc[key]['column']\n",
        "#     colLength = (int(sorted_groups[sorted_groups['column'] \\\n",
        "#       == col]['group_index'].max()) + 2)\n",
        "#     currRow = (row + 1)\n",
        "\n",
        "#     y_val = maxRow/colLength * currRow\n",
        "#     pos[key] = (val[0], y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqXFSk15ZoBY",
        "outputId": "03d2aa49-55e2-43c0-a374-b0ecafe7bfe2"
      },
      "outputs": [],
      "source": [
        "len(node_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "671rh_vWIGRY",
        "outputId": "0b7f4a87-0ecf-416c-c030-bd7b802dc1fc"
      },
      "outputs": [],
      "source": [
        "x = np.array(list(pos.values())) # gets the positions\n",
        "adj = nx.to_scipy_sparse_array(G).tocoo() #makes adjacency matrix\n",
        "weights = adj.data #gets the weigths\n",
        "\n",
        "# Extract edges from embedding and adjacency matrix\n",
        "edges = np.stack([x[adj.row], x[adj.col]], axis=1)\n",
        "\n",
        "# Compute FDEB\n",
        "edges_fdeb = fdeb(edges) #bundles edges\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(40, 20), dpi=150)\n",
        "\n",
        "# Gets correct colors and line widths\n",
        "for edge, weight in zip(edges_fdeb, weights):\n",
        "    if weight >= 0:\n",
        "      line = collections.LineCollection([edge], color=\"black\", linewidth=weight ** 2, alpha=1)\n",
        "    else:\n",
        "      line = collections.LineCollection([edge], color=\"red\", linewidth=weight ** 2, alpha=1)\n",
        "    ax.add_collection(line)\n",
        "\n",
        "#node names\n",
        "nx.draw_networkx_labels(G, pos, font_size=18, font_color='purple', font_weight='bold')\n",
        "\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos=pos, node_size=node_size, node_color='skyblue')\n",
        "\n",
        "\n",
        "plt.title('Spring MNIST FDEB')\n",
        "\n",
        "# Hide axes\n",
        "ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsXLUkWKI2Xr"
      },
      "source": [
        "### ChatGPTs attempt at making FDEB useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "escb2NKVIpjF"
      },
      "outputs": [],
      "source": [
        "# # Function to preprocess edges for edge bundling\n",
        "# # essentially, it trys to add a point in the middle of the edges, which will\n",
        "# # cause for better attraction, it was also trying (and failing) to factor in weights\n",
        "# def preprocess_edges(edges, node_positions):\n",
        "#     bundled_edges = []\n",
        "#     bundled_weights = []\n",
        "#     for target_node in G.nodes():\n",
        "#         incoming_edges = [edge for edge in edges if edge[1] == target_node] #gets edges that share the dest/target node\n",
        "#         if len(incoming_edges) <= 1:\n",
        "#             continue\n",
        "\n",
        "#         mean_position = np.mean([pos[edge[0]] for edge in incoming_edges], axis=0) # averages the positions of the source nodes\n",
        "\n",
        "#         # Move control points towards the mean position\n",
        "#         for edge in incoming_edges:\n",
        "#             source = pos[edge[0]]\n",
        "#             target = pos[edge[1]]\n",
        "#             control_points = [source, mean_position, target]\n",
        "#             bundled_edges.append(control_points) # attempts to use those three points in the FDEB along with the weights\n",
        "#             bundled_weights.append(G[edge[0]][edge[1]]['weight'])  # makes an array of the weights\n",
        "\n",
        "#     return np.array(bundled_edges), np.array(bundled_weights)\n",
        "\n",
        "# # Preprocess edges for bundling\n",
        "# edges = list(G.edges())\n",
        "# bundled_edges, bundled_weights = preprocess_edges(edges, pos)\n",
        "\n",
        "# # Perform edge bundling with FDEB\n",
        "# edges_fdeb = fdeb(bundled_edges) #, bundled_weights) #took this off because the linear algebra math wasn't mathing, probably fixable tbh\n",
        "\n",
        "# plt.figure(figsize=(20, 12))\n",
        "\n",
        "# # adds edge colors and thickness\n",
        "# for edge, weight in zip(edges_fdeb, bundled_weights):\n",
        "#     if weight>=0:\n",
        "#       line = collections.LineCollection([edge], color='black', linewidth=weight ** 2)\n",
        "#     else:\n",
        "#       line = collections.LineCollection([edge], color='red', linewidth=weight ** 2)\n",
        "#     plt.gca().add_collection(line)\n",
        "\n",
        "# # nodes, node color, and node size\n",
        "# nx.draw_networkx_nodes(G, pos, node_size=500, node_color='lightblue')\n",
        "\n",
        "# # node names\n",
        "# nx.draw_networkx_labels(G, pos, font_size=12, font_color='purple', font_weight='bold')\n",
        "\n",
        "# plt.title('Spring Iris FDEB with mean values')\n",
        "# plt.axis('off')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f6dIR3HJDfi"
      },
      "source": [
        "### NetGraph attempt at bundling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st0mkQJNI_Im"
      },
      "outputs": [],
      "source": [
        "# node_to_community = {}\n",
        "# for node in G.nodes():\n",
        "#   node_to_community[node] = int(node.split('_')[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O25MvYc-Jd7R"
      },
      "outputs": [],
      "source": [
        "# #adds node color based on community\n",
        "# community_to_color = {\n",
        "#     0 : 'tab:blue',\n",
        "#     1 : 'tab:orange',\n",
        "#     2 : 'tab:green',\n",
        "#     3 : 'tab:red',\n",
        "# }\n",
        "# node_color = {node: community_to_color[community_id] \\\n",
        "#               for node, community_id in node_to_community.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csi-KmZk9nsR"
      },
      "outputs": [],
      "source": [
        "# # A dictionary where key = edge and val = np.array(weight)\n",
        "# width = {edge: np.array(G[edge[0]][edge[1]]['weight']).item() for edge in G.edges()}\n",
        "\n",
        "# edge_colors = {edge: 'black' if np.array(G[edge[0]][edge[1]]['weight']).item() >= 0 else 'red' for edge in G.edges()}\n",
        "\n",
        "# edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "\n",
        "# pos2 = {} # Makes a dictionary where key = node and val = np.array(x, y)\n",
        "# for node, val in pos.items():\n",
        "#   pos2[node]= np.array([val[0], val[1]])\n",
        "\n",
        "# # Use the edge_layout option to bundle the edges together\n",
        "# fig, ax = plt.subplots(figsize = (30, 50))\n",
        "# Gbundle = Graph(G,\n",
        "#       node_color=node_color,\n",
        "#       # node_size = 10,\n",
        "#       edge_width = width,\n",
        "#       edge_color = edge_colors,\n",
        "#       node_layout=pos2,\n",
        "#       edge_labels = edge_labels,\n",
        "#       # node_layout='community', node_layout_kwargs=dict(node_to_community=node_to_community),\n",
        "#       edge_layout='bundled', # this is where bundling is made possible,\n",
        "#       node_labels = True,\n",
        "#       edge_alpha = 1,\n",
        "#       ax=ax,\n",
        "# )\n",
        "# # Gbundle.node_positions =\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YJhKHsYKZ31"
      },
      "source": [
        "### Midpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8uSBPEgJr9m"
      },
      "outputs": [],
      "source": [
        "#create midpoints between columns with white nodes. the y val of the midpt is based on the output node\n",
        "\n",
        "weights = model.weights\n",
        "# Create a Multi Drected graph\n",
        "G = nx.MultiDiGraph()\n",
        "\n",
        "pos = {}\n",
        "col = 0\n",
        "mdpt_weights = {}\n",
        "\n",
        "i = 0\n",
        "while i < len(weights): #gets weights associated with the a column\n",
        "  w = weights[i] #ws are weights between two layers\n",
        "\n",
        "  for sourceRow in range(w.shape[0]):\n",
        "    # if col == 0: # makes the first layer of nodes' names input the variables\n",
        "    #   # rows and columns are kept in the name to help with determining pos\n",
        "    #   source_node = ind_input_names[sourceRow] + '_' + str(sourceRow) + '_' + str(col)\n",
        "    # else:\n",
        "    source_node = 'l_' + str(sourceRow) + '_' + str(col)\n",
        "\n",
        "    if source_node not in pos.keys():\n",
        "\n",
        "      sourceColumn = sorted_groups.loc[source_node]['column']\n",
        "      colLength = (int(sorted_groups[sorted_groups['column'] \\\n",
        "        == sourceColumn]['group_index'].max()) + 2)\n",
        "      currRow = (sourceRow + 1)\n",
        "\n",
        "      pos[source_node] = (col, maxRow/colLength * currRow * 5)\n",
        "\n",
        "    for row in range(w.shape[1]): #w.shape[1] is number of rows in next column\n",
        "\n",
        "      midpt = 'mp_' + str(row) + '_' + str(col + 1)\n",
        "      if not G.has_edge(source_node, midpt): #neccessary as this is a multigraph\n",
        "        G.add_edge(source_node, midpt, weight = np.array(w[sourceRow][row]).item())\n",
        "\n",
        "      # if col+1 == len(weights)//2: #if last layer, makes node names the output variables\n",
        "      #   dest_node = ind_output_names[row] + '_' + str(row) + '_' + str(col + 1)\n",
        "      # else:\n",
        "      dest_node = 'l_' + str(row) + '_' + str(col + 1)\n",
        "\n",
        "      if dest_node not in pos.keys():\n",
        "        destColumn = sorted_groups.loc[dest_node]['column']\n",
        "        colLength = (int(sorted_groups[sorted_groups['column'] \\\n",
        "          == destColumn]['group_index'].max()) + 2)\n",
        "        currRow = sorted_groups.loc[dest_node]['group_index'] + 1\n",
        "        pos[dest_node] = (col + 1, (maxRow/colLength * currRow) * 5)\n",
        "\n",
        "      if midpt not in pos.keys():\n",
        "        pos[midpt] = (col + .5, maxRow/colLength * currRow * 5)\n",
        "\n",
        "      #adds up the total pos and neg weights from mdpt to dest nodes\n",
        "      edge_weight = np.array(w[sourceRow][row]).item()\n",
        "      mdpt_weights.setdefault(midpt, (0, 0)) # dictionary: keys = midpt nodes, vals = coords\n",
        "\n",
        "      positive_weight = mdpt_weights[midpt][0]\n",
        "      negative_weight = mdpt_weights[midpt][1]\n",
        "\n",
        "      if edge_weight >= 0:\n",
        "        positive_weight += edge_weight\n",
        "      else:\n",
        "        negative_weight += edge_weight\n",
        "\n",
        "      mdpt_weights[midpt] = (positive_weight, negative_weight)\n",
        "\n",
        "  i += 2\n",
        "  col += 1\n",
        "\n",
        "for key, val in mdpt_weights.items():\n",
        "  #renames last layer to be output names\n",
        "  # if int(key.split('_')[2]) == len(weights)//2:\n",
        "  #   dest_node = ind_output_names[int(key.split('_')[1])] + '_' + key.split('_')[1] + '_' + key.split('_')[2]\n",
        "  # else:\n",
        "  dest_node = 'l_' + key.split('_')[1] + '_' + key.split('_')[2]\n",
        "\n",
        "  # makes the two edges (pos and neg) btwn mdpt and actual layers, if either pos or neg or 0 doens't do it\n",
        "  if val[0] != 0:\n",
        "    G.add_edge(key, dest_node, weight = float(val[0])) # positive weight\n",
        "  if val[1] != 0:\n",
        "    G.add_edge(key, dest_node, weight = float(val[1])) # negative weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "eqN60tiKJwZH",
        "outputId": "fbde68b2-3e4a-496c-b7e2-2a71f671bb95"
      },
      "outputs": [],
      "source": [
        "edge_colors = ['black' if G[u][v][key]['weight'] >= 0 else 'red' for u, v, key in G.edges(keys=True)] # Edge colors based on weight\n",
        "width = [math.log2(abs(G[u][v][key]['weight'])) for u, v, key in G.edges(keys=True)] # Edge width based on weight\n",
        "node_list = [node for node in G.nodes() if node[:2] != 'mp']\n",
        "connectionStyle = []\n",
        "node_size = []\n",
        "dest_node_size = {}\n",
        "edge_labels = {}\n",
        "\n",
        "\n",
        "for u, v, key, d in G.edges(keys=True, data = True):\n",
        "  #determines node size\n",
        "  if v[:2] != 'mp':\n",
        "    dest_node_size[v] = dest_node_size.get(v, 0) + abs(d['weight'])\n",
        "\n",
        "  #determines connection style\n",
        "  if u.split('_')[0] != 'mp': #if source node isn't a mdpt, edge is straight\n",
        "    connectionStyle.append('arc3')\n",
        "  else:\n",
        "    try: # if both a pos and neg edge exist btwn midpt and dest then, pos curves up, and neg curces down\n",
        "      if G[u][v][0]['weight'] != 0 and G[u][v][1]['weight'] != 0:\n",
        "        if key == 0:\n",
        "          connectionStyle.append(f'arc3,rad={-0.20}')\n",
        "        else:\n",
        "          connectionStyle.append(f'arc3,rad={0.20}')\n",
        "    except KeyError as e: # if only a positive or negative edge btwn mdpt and dest, then edge is straight\n",
        "      connectionStyle.append('arc3')\n",
        "\n",
        "  # makes edge labels\n",
        "  if u.split('_')[0] != 'mp': # if not source node isn't a mp then just give typical weights\n",
        "    edge_labels[(u, v, key)] = f\"{G[u][v][key]['weight']:.2f}\"\n",
        "  else:\n",
        "    try:\n",
        "      if G[u][v][0]['weight'] != 0 and G[u][v][1]['weight'] != 0:\n",
        "        # if both outgoing weights of positive and negative give Positive, negative\n",
        "        edge_labels[(u, v, key)] = f\"{G[u][v][0]['weight']:.2f}, {G[u][v][1]['weight']:.2f}\"\n",
        "    except KeyError as e:\n",
        "      #if only one key give a singular weight\n",
        "      edge_labels[(u, v, key)] = f\"{G[u][v][key]['weight']:.2f}\"\n",
        "\n",
        "for node in G.nodes():\n",
        "  if node[:2] != 'mp':\n",
        "    col = int(node.split('_')[2]) - 1\n",
        "    if node in dest_node_size.keys():\n",
        "      node_size.append(dest_node_size[node]/colSize[col] * 4000)\n",
        "    else:\n",
        "      node_size.append(1000)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(40, 20))\n",
        "\n",
        "#draws none mdpt nodes, with color and size\n",
        "nx.draw_networkx_nodes(G, pos=pos, nodelist = node_list, node_size=node_size, node_color='skyblue')\n",
        "\n",
        "label_pos = {} #makes pos for node labels, to prevent mdpt labeling\n",
        "for node, coords in pos.items():\n",
        "  if node.split('_')[0] != 'mp':\n",
        "    label_pos[node] = np.array([coords[0], coords[1]]) # if not mp gives lable\n",
        "  else:\n",
        "    label_pos[node] = np.array([-55000000, -550000000]) # if mp throws the labels way out there because we don't want to see them\n",
        "\n",
        "# node names\n",
        "nx.draw_networkx_labels(G, label_pos, font_size=18, font_color='purple', font_weight='bold')\n",
        "\n",
        "\n",
        "\n",
        "# Draw edges individually with specified connection styles (adds a curve if more than two edges per two nodes)\n",
        "for (u, v, key), color, style, w in zip(G.edges(keys=True), edge_colors, connectionStyle, width):\n",
        "    nx.draw_networkx_edges(\n",
        "        G, pos,\n",
        "        edgelist=[(u, v, key)],\n",
        "        edge_color=color,\n",
        "        connectionstyle=style,\n",
        "        width=w,\n",
        "        arrows=True\n",
        "    )\n",
        "\n",
        "# draws the edge labels\n",
        "for u, v, key in G.edges(keys=True):\n",
        "    specific_edge_labels = {(u, v, key): edge_labels[(u, v, key)]}\n",
        "    row = int(u.split('_')[1])\n",
        "    index = int(u.split('_')[2])\n",
        "    if u[:2] == 'mp':\n",
        "      nx.draw_networkx_edge_labels(G, pos, edge_labels=specific_edge_labels, font_color='black', font_size=12, label_pos = 0.5)\n",
        "#    else:\n",
        "#       nx.draw_networkx_edge_labels(G, pos, edge_labels=specific_edge_labels, font_color='black', font_size=12, label_pos = (row + 1) / (colSize[index]+2))\n",
        "\n",
        "plt.title('Spring MNIST Destination Based Edge Bundling')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
